#!/usr/bin/env python3
"""
å¿«é€Ÿæ¸…ç†æ˜æ˜¾æœ‰é—®é¢˜çš„CSVæ–‡ä»¶

ä¸“é—¨å¤„ç†ä»¥ä¸‹é—®é¢˜ï¼š
1. æ‰€æœ‰ä»·æ ¼æ•°æ®ä¸ºç©ºçš„æ–‡ä»¶
2. æ–‡ä»¶å¤§å°å¼‚å¸¸å°çš„æ–‡ä»¶
3. è¡Œæ•°è¿‡å°‘çš„æ–‡ä»¶
4. æ— æ³•è¯»å–çš„æŸåæ–‡ä»¶
"""

import argparse
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import List, Tuple

import pandas as pd
from tqdm import tqdm


def quick_check_file(csv_path: Path) -> Tuple[bool, str]:
    """å¿«é€Ÿæ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ˜æ˜¾é—®é¢˜"""
    try:
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå°äº1KBå¯èƒ½æœ‰é—®é¢˜ï¼‰
        file_size = csv_path.stat().st_size
        if file_size < 1024:
            return False, f"æ–‡ä»¶è¿‡å°({file_size}å­—èŠ‚)"
        
        # å°è¯•è¯»å–æ–‡ä»¶
        df = pd.read_csv(csv_path)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
        if df.empty:
            return False, "æ–‡ä»¶ä¸ºç©º"
        
        # æ£€æŸ¥è¡Œæ•°
        if len(df) < 10:
            return False, f"æ•°æ®è¡Œæ•°è¿‡å°‘({len(df)}è¡Œ)"
        
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ["date", "open", "high", "low", "close", "volume"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return False, f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}"
        
        # æ£€æŸ¥ä»·æ ¼æ•°æ®æ˜¯å¦å…¨ä¸ºç©º
        price_columns = ["open", "high", "low", "close"]
        price_data_exists = any(
            not df[col].isna().all() 
            for col in price_columns 
            if col in df.columns
        )
        
        if not price_data_exists:
            return False, "æ‰€æœ‰ä»·æ ¼æ•°æ®ä¸ºç©º"
        
        # æ£€æŸ¥ç©ºå€¼æ¯”ä¾‹
        total_rows = len(df)
        for col in price_columns:
            if col in df.columns:
                null_ratio = df[col].isna().sum() / total_rows
                if null_ratio > 0.8:  # è¶…è¿‡80%ä¸ºç©º
                    return False, f"{col}åˆ—ç©ºå€¼æ¯”ä¾‹è¿‡é«˜({null_ratio:.1%})"
        
        return True, "æ•°æ®æ­£å¸¸"
        
    except Exception as e:
        return False, f"è¯»å–å¤±è´¥: {str(e)}"


def scan_and_clean(data_dir: Path, backup_dir: Path = None, dry_run: bool = False) -> None:
    """æ‰«æå¹¶æ¸…ç†é—®é¢˜æ–‡ä»¶"""
    
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶ï¼ˆæ’é™¤å¸‚å€¼æ–‡ä»¶ï¼‰
    csv_files = [f for f in data_dir.glob("*.csv") if not f.name.startswith("mktcap_")]
    
    if not csv_files:
        print("ğŸ“ æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        return
    
    print(f"ğŸ“Š å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    if backup_dir and not dry_run:
        backup_dir.mkdir(parents=True, exist_ok=True)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "total": len(csv_files),
        "problematic": 0,
        "deleted": 0,
        "backed_up": 0,
        "errors": 0
    }
    
    problematic_files = []
    
    # æ‰«ææ–‡ä»¶
    print("\nğŸ” æ‰«ææ–‡ä»¶è´¨é‡...")
    for csv_path in tqdm(csv_files, desc="æ‰«æè¿›åº¦"):
        is_good, reason = quick_check_file(csv_path)
        
        if not is_good:
            stats["problematic"] += 1
            problematic_files.append((csv_path, reason))
    
    if not problematic_files:
        print("âœ… æ‰€æœ‰æ–‡ä»¶éƒ½æ­£å¸¸ï¼Œæ— éœ€æ¸…ç†")
        return
    
    print(f"\nâš ï¸  å‘ç° {len(problematic_files)} ä¸ªé—®é¢˜æ–‡ä»¶:")
    for csv_path, reason in problematic_files:
        print(f"  - {csv_path.name}: {reason}")
    
    # æ¸…ç†æ–‡ä»¶
    if dry_run:
        print(f"\nğŸ” [æ¨¡æ‹Ÿæ¨¡å¼] å°†åˆ é™¤ {len(problematic_files)} ä¸ªæ–‡ä»¶")
        for csv_path, reason in problematic_files:
            print(f"  [æ¨¡æ‹Ÿåˆ é™¤] {csv_path.name}: {reason}")
    else:
        print(f"\nğŸ—‘ï¸  å¼€å§‹æ¸…ç† {len(problematic_files)} ä¸ªé—®é¢˜æ–‡ä»¶...")
        
        for csv_path, reason in tqdm(problematic_files, desc="æ¸…ç†è¿›åº¦"):
            try:
                # å¤‡ä»½æ–‡ä»¶
                if backup_dir:
                    backup_path = backup_dir / csv_path.name
                    shutil.copy2(csv_path, backup_path)
                    stats["backed_up"] += 1
                
                # åˆ é™¤æ–‡ä»¶
                csv_path.unlink()
                stats["deleted"] += 1
                
            except Exception as e:
                print(f"âŒ å¤„ç† {csv_path.name} å¤±è´¥: {e}")
                stats["errors"] += 1
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"\nğŸ“‹ æ¸…ç†å®Œæˆç»Ÿè®¡:")
    print(f"  æ€»æ–‡ä»¶æ•°: {stats['total']}")
    print(f"  é—®é¢˜æ–‡ä»¶æ•°: {stats['problematic']}")
    print(f"  åˆ é™¤æ–‡ä»¶æ•°: {stats['deleted']}")
    if backup_dir:
        print(f"  å¤‡ä»½æ–‡ä»¶æ•°: {stats['backed_up']}")
        print(f"  å¤‡ä»½ä½ç½®: {backup_dir}")
    print(f"  é”™è¯¯æ•°: {stats['errors']}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    if not dry_run and problematic_files:
        report_path = data_dir / f"quick_clean_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(f"å¿«é€Ÿæ¸…ç†æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ•°æ®ç›®å½•: {data_dir}\n")
            f.write(f"å¤‡ä»½ç›®å½•: {backup_dir}\n\n")
            f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
            for key, value in stats.items():
                f.write(f"  {key}: {value}\n")
            f.write("\né—®é¢˜æ–‡ä»¶åˆ—è¡¨:\n")
            for csv_path, reason in problematic_files:
                f.write(f"  {csv_path.name}: {reason}\n")
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


def main():
    parser = argparse.ArgumentParser(description="å¿«é€Ÿæ¸…ç†æ˜æ˜¾æœ‰é—®é¢˜çš„CSVæ–‡ä»¶")
    parser.add_argument("--data-dir", default="./data", help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--backup-dir", help="å¤‡ä»½ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸ºdata_backupï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…åˆ é™¤æ–‡ä»¶")
    parser.add_argument("--no-backup", action="store_true", help="åˆ é™¤æ—¶ä¸å¤‡ä»½æ–‡ä»¶")
    
    args = parser.parse_args()
    
    data_dir = Path(args.data_dir)
    backup_dir = None
    
    if not args.no_backup:
        if args.backup_dir:
            backup_dir = Path(args.backup_dir)
        else:
            backup_dir = data_dir.parent / "data_backup"
    
    print("ğŸ§¹ å¿«é€Ÿæ•°æ®æ¸…ç†å·¥å…·")
    print("=" * 30)
    print(f"æ•°æ®ç›®å½•: {data_dir}")
    if backup_dir:
        print(f"å¤‡ä»½ç›®å½•: {backup_dir}")
    print(f"æ¨¡å¼: {'æ¨¡æ‹Ÿè¿è¡Œ' if args.dry_run else 'å®é™…æ¸…ç†'}")
    print()
    
    try:
        scan_and_clean(data_dir, backup_dir, args.dry_run)
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"âŒ æ¸…ç†è¿‡ç¨‹å‡ºé”™: {e}")


if __name__ == "__main__":
    main()
